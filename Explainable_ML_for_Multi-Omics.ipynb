{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f14f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# CONFIGURATION\n",
    "###############################################################\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_dir: str = r\"C:\\Users\\VN-ChoHyunJae\\Downloads\\msk_chord_2024\\msk_chord_2024\"\n",
    "    batch_size: int = 64\n",
    "    embed_dim: int = 128\n",
    "    hyper_dim: int = 128\n",
    "    latent_dim: int = 128\n",
    "    max_genes_per_patient: int = 200\n",
    "    lr: float = 1e-3\n",
    "    epochs: int = 30\n",
    "    weight_decay: float = 1e-4\n",
    "    survival_rank_margin: float = 1.0\n",
    "    geometry_lambda: float = 0.1\n",
    "    counterfactual_lambda: float = 0.05\n",
    "    device: str = \"cuda\"\n",
    "\n",
    "\n",
    "CFG = Config()\n",
    "DEVICE = torch.device(CFG.device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# DATA LOADING\n",
    "###############################################################\n",
    "\n",
    "class MSKDataLoader:\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "\n",
    "    def load_raw(self):\n",
    "\n",
    "        clinical_patient = pd.read_csv(\n",
    "            os.path.join(self.config.data_dir, \"data_clinical_patient.txt\"),\n",
    "            sep=\"\\t\",\n",
    "            comment=\"#\"\n",
    "        )\n",
    "\n",
    "        clinical_sample = pd.read_csv(\n",
    "            os.path.join(self.config.data_dir, \"data_clinical_sample.txt\"),\n",
    "            sep=\"\\t\",\n",
    "            comment=\"#\"\n",
    "        )\n",
    "\n",
    "        mutations = pd.read_csv(\n",
    "            os.path.join(self.config.data_dir, \"data_mutations.txt\"),\n",
    "            sep=\"\\t\",\n",
    "            comment=\"#\",\n",
    "            low_memory=False\n",
    "        )\n",
    "\n",
    "        treatment = pd.read_csv(\n",
    "            os.path.join(self.config.data_dir, \"data_timeline_treatment.txt\"),\n",
    "            sep=\"\\t\",\n",
    "            comment=\"#\"\n",
    "        )\n",
    "\n",
    "        return clinical_patient, clinical_sample, mutations, treatment\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# PREPROCESSING\n",
    "###############################################################\n",
    "\n",
    "class MSKPreprocessor:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def preprocess(self, clinical_patient, clinical_sample, mutations, treatment):\n",
    "\n",
    "        clinical_sample = clinical_sample.merge(\n",
    "            clinical_patient,\n",
    "            on=\"PATIENT_ID\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "\n",
    "        clinical_sample = clinical_sample[\n",
    "            [\"SAMPLE_ID\", \"PATIENT_ID\", \"OS_MONTHS\", \"OS_STATUS\"]\n",
    "        ].dropna()\n",
    "\n",
    "        clinical_sample[\"event\"] = clinical_sample[\"OS_STATUS\"].apply(\n",
    "            lambda x: 1 if \"DECEASED\" in str(x).upper() else 0\n",
    "        )\n",
    "\n",
    "        mutations = mutations.merge(\n",
    "            clinical_sample[[\"SAMPLE_ID\", \"PATIENT_ID\"]],\n",
    "            left_on=\"Tumor_Sample_Barcode\",\n",
    "            right_on=\"SAMPLE_ID\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "\n",
    "        patient_genes = defaultdict(set)\n",
    "\n",
    "        for _, row in mutations.iterrows():\n",
    "            gene = row[\"Hugo_Symbol\"]\n",
    "            pid = row[\"PATIENT_ID\"]\n",
    "            if pd.notna(gene):\n",
    "                patient_genes[pid].add(gene)\n",
    "\n",
    "        treatment = treatment.sort_values(\"START_DATE\")\n",
    "        last_treatment = treatment.groupby(\"PATIENT_ID\").tail(1)\n",
    "\n",
    "        treatment_map = dict(zip(last_treatment[\"PATIENT_ID\"], last_treatment[\"AGENT\"]))\n",
    "\n",
    "        data_rows = []\n",
    "\n",
    "        for _, row in clinical_sample.iterrows():\n",
    "            pid = row[\"PATIENT_ID\"]\n",
    "            if pid in patient_genes:\n",
    "                data_rows.append({\n",
    "                    \"PATIENT_ID\": pid,\n",
    "                    \"genes\": list(patient_genes[pid]),\n",
    "                    \"time\": float(row[\"OS_MONTHS\"]),\n",
    "                    \"event\": int(row[\"event\"]),\n",
    "                    \"treatment\": treatment_map.get(pid, \"UNKNOWN\")\n",
    "                })\n",
    "\n",
    "        df = pd.DataFrame(data_rows)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# GENE VOCABULARY\n",
    "###############################################################\n",
    "\n",
    "class GeneVocabulary:\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.gene2idx = self.build_vocab(df)\n",
    "        self.idx2gene = {v: k for k, v in self.gene2idx.items()}\n",
    "\n",
    "    def build_vocab(self, df):\n",
    "\n",
    "        all_genes = set()\n",
    "        for genes in df[\"genes\"]:\n",
    "            all_genes.update(genes)\n",
    "\n",
    "        gene2idx = {g: i + 1 for i, g in enumerate(sorted(all_genes))}\n",
    "        gene2idx[\"PAD\"] = 0\n",
    "\n",
    "        return gene2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gene2idx)\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# SPARSE HYPERGRAPH CONSTRUCTION (GENE CO-OCCURRENCE)\n",
    "###############################################################\n",
    "\n",
    "class HypergraphBuilder:\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, gene2idx: Dict[str, int]):\n",
    "        self.df = df\n",
    "        self.gene2idx = gene2idx\n",
    "\n",
    "    def build(self) -> torch.Tensor:\n",
    "\n",
    "        gene_cooccur = defaultdict(set)\n",
    "\n",
    "        for genes in self.df[\"genes\"]:\n",
    "            for g in genes:\n",
    "                gene_cooccur[g].update(genes)\n",
    "\n",
    "        rows = []\n",
    "        cols = []\n",
    "\n",
    "        edge_index = 0\n",
    "\n",
    "        for gene, neighbors in gene_cooccur.items():\n",
    "            for g in neighbors:\n",
    "                if g in self.gene2idx:\n",
    "                    rows.append(self.gene2idx[g])\n",
    "                    cols.append(edge_index)\n",
    "            edge_index += 1\n",
    "\n",
    "        indices = torch.tensor([rows, cols], dtype=torch.long)\n",
    "        values = torch.ones(len(rows))\n",
    "\n",
    "        H = torch.sparse_coo_tensor(\n",
    "            indices,\n",
    "            values,\n",
    "            size=(len(self.gene2idx), edge_index)\n",
    "        )\n",
    "\n",
    "        return H.coalesce().to(DEVICE)\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# DATASET\n",
    "###############################################################\n",
    "\n",
    "class MSKDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        gene_vocab: GeneVocabulary,\n",
    "        treatment_encoder: LabelEncoder,\n",
    "        max_genes: int\n",
    "    ):\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.gene2idx = gene_vocab.gene2idx\n",
    "        self.treatment_encoder = treatment_encoder\n",
    "        self.max_genes = max_genes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def encode_genes(self, genes: List[str]) -> List[int]:\n",
    "\n",
    "        ids = [self.gene2idx.get(g, 0) for g in genes]\n",
    "        ids = ids[:self.max_genes]\n",
    "\n",
    "        if len(ids) < self.max_genes:\n",
    "            ids += [0] * (self.max_genes - len(ids))\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        gene_ids = self.encode_genes(row[\"genes\"])\n",
    "\n",
    "        treatment_id = self.treatment_encoder.transform(\n",
    "            [row[\"treatment\"]]\n",
    "        )[0]\n",
    "\n",
    "        return {\n",
    "            \"gene_ids\": torch.tensor(gene_ids, dtype=torch.long),\n",
    "            \"context\": torch.tensor(treatment_id, dtype=torch.long),\n",
    "            \"time\": torch.tensor(row[\"time\"], dtype=torch.float32),\n",
    "            \"event\": torch.tensor(row[\"event\"], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# DATALOADER FACTORY\n",
    "###############################################################\n",
    "\n",
    "def build_dataloaders(df, gene_vocab):\n",
    "\n",
    "    treatment_encoder = LabelEncoder()\n",
    "    df[\"treatment\"] = df[\"treatment\"].fillna(\"UNKNOWN\")\n",
    "    treatment_encoder.fit(df[\"treatment\"])\n",
    "\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dataset = MSKDataset(\n",
    "        train_df,\n",
    "        gene_vocab,\n",
    "        treatment_encoder,\n",
    "        CFG.max_genes_per_patient\n",
    "    )\n",
    "\n",
    "    val_dataset = MSKDataset(\n",
    "        val_df,\n",
    "        gene_vocab,\n",
    "        treatment_encoder,\n",
    "        CFG.max_genes_per_patient\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, treatment_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab6540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# TRUE HYPERGRAPH PROPAGATION (CORRECTED GLOBAL VERSION)\n",
    "###############################################################\n",
    "\n",
    "class HypergraphPropagation(nn.Module):\n",
    "    \"\"\"\n",
    "    True global hypergraph propagation:\n",
    "        X' = Dv^-1/2 H De^-1 H^T Dv^-1/2 X\n",
    "    Where X is full gene embedding matrix (|V| x D)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, H: torch.Tensor):\n",
    "        super().__init__()\n",
    "\n",
    "        self.H = H.coalesce()\n",
    "        self.num_nodes, self.num_edges = self.H.size()\n",
    "\n",
    "        self.compute_degrees()\n",
    "\n",
    "    def compute_degrees(self):\n",
    "\n",
    "        H = self.H\n",
    "\n",
    "        Dv = torch.sparse.sum(H, dim=1).to_dense()\n",
    "        De = torch.sparse.sum(H, dim=0).to_dense()\n",
    "\n",
    "        self.register_buffer(\"Dv_inv_sqrt\", torch.pow(Dv + 1e-6, -0.5))\n",
    "        self.register_buffer(\"De_inv\", torch.pow(De + 1e-6, -1.0))\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        # X: (|V|, D)\n",
    "\n",
    "        H = self.H\n",
    "\n",
    "        Dv_inv_sqrt = self.Dv_inv_sqrt.unsqueeze(1)\n",
    "        De_inv = self.De_inv.unsqueeze(1)\n",
    "\n",
    "        # Normalize nodes\n",
    "        X = X * Dv_inv_sqrt\n",
    "\n",
    "        # H^T X\n",
    "        Ht = torch.sparse_coo_tensor(\n",
    "            torch.stack([H.indices()[1], H.indices()[0]]),\n",
    "            H.values(),\n",
    "            size=(self.num_edges, self.num_nodes),\n",
    "            device=X.device\n",
    "        )\n",
    "\n",
    "        HX = torch.sparse.mm(Ht, X)\n",
    "        HX = HX * De_inv\n",
    "\n",
    "        X_prop = torch.sparse.mm(H, HX)\n",
    "        X_prop = X_prop * Dv_inv_sqrt\n",
    "\n",
    "        return X_prop\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# CONTEXT-CONDITIONED HYPERGRAPH ATTENTION\n",
    "###############################################################\n",
    "\n",
    "class ContextHypergraphAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_dim, context_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self.context_proj = nn.Linear(context_dim, embed_dim)\n",
    "\n",
    "        self.scale = embed_dim ** 0.5\n",
    "\n",
    "    def forward(self, X, context):\n",
    "\n",
    "        # X: (B, M, D)\n",
    "        # context: (B, D_c)\n",
    "\n",
    "        Q = self.query(X)\n",
    "        K = self.key(X)\n",
    "        V = self.value(X)\n",
    "\n",
    "        attn_scores = torch.matmul(Q, K.transpose(1, 2)) / self.scale\n",
    "\n",
    "        context_bias = self.context_proj(context).unsqueeze(1)\n",
    "        attn_scores = attn_scores + torch.matmul(Q, context_bias.transpose(1,2))\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        X_att = torch.matmul(attn_weights, V)\n",
    "\n",
    "        return X_att\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# SURVIVAL GEOMETRY REGULARIZER\n",
    "###############################################################\n",
    "\n",
    "class SurvivalGeometryRegularizer(nn.Module):\n",
    "    \"\"\"\n",
    "    Enforces risk-ordered latent manifold.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, z, risk, time, event):\n",
    "\n",
    "        B = z.size(0)\n",
    "\n",
    "        loss = 0.0\n",
    "        count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            for j in range(B):\n",
    "                if time[i] < time[j] and event[i] == 1:\n",
    "                    loss += F.relu(self.margin - (risk[j] - risk[i]))\n",
    "                    count += 1\n",
    "\n",
    "        if count == 0:\n",
    "            return torch.tensor(0.0, device=z.device)\n",
    "\n",
    "        return loss / count\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# COUNTERFACTUAL OPERATOR\n",
    "###############################################################\n",
    "\n",
    "class CounterfactualOperator:\n",
    "\n",
    "    def remove_gene(self, gene_ids, remove_idx):\n",
    "\n",
    "        # gene_ids: (B, M)\n",
    "        # remove_idx: (B,)\n",
    "\n",
    "        remove_idx = remove_idx.unsqueeze(1)  # (B,1)\n",
    "\n",
    "        mask = (gene_ids != remove_idx).long()\n",
    "\n",
    "        return gene_ids * mask\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# FULL MODEL\n",
    "###############################################################\n",
    "\n",
    "class MechanismHypergraphModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_genes,\n",
    "        num_treatments,\n",
    "        H_sparse\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gene_embed = nn.Embedding(num_genes, CFG.embed_dim)\n",
    "        self.treatment_embed = nn.Embedding(num_treatments, CFG.embed_dim)\n",
    "\n",
    "        self.hyper_prop = HypergraphPropagation(H_sparse)\n",
    "\n",
    "        self.context_attention = ContextHypergraphAttention(\n",
    "            CFG.embed_dim,\n",
    "            CFG.embed_dim\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.latent_proj = nn.Linear(CFG.embed_dim, CFG.latent_dim)\n",
    "        self.risk_head = nn.Linear(CFG.latent_dim, 1)\n",
    "\n",
    "        self.geometry_reg = SurvivalGeometryRegularizer(\n",
    "            margin=CFG.survival_rank_margin\n",
    "        )\n",
    "\n",
    "        self.counterfactual = CounterfactualOperator()\n",
    "\n",
    "    def forward(self, gene_ids, context_ids):\n",
    "\n",
    "        # 1️⃣ Global propagation\n",
    "        E = self.gene_embed.weight            # (|V|, D)\n",
    "        E_prop = self.hyper_prop(E)           # (|V|, D)\n",
    "\n",
    "        # 2️⃣ Gather patient genes\n",
    "        X = E_prop[gene_ids]                  # (B, M, D)\n",
    "\n",
    "        context_vec = self.treatment_embed(context_ids)\n",
    "\n",
    "        # 3️⃣ Context attention\n",
    "        X_att = self.context_attention(X, context_vec)\n",
    "\n",
    "        # 4️⃣ Pool\n",
    "        X_att = X_att.transpose(1, 2)\n",
    "        z = self.pool(X_att).squeeze(-1)\n",
    "\n",
    "        z = self.latent_proj(z)\n",
    "        risk = self.risk_head(z).squeeze()\n",
    "\n",
    "        return risk, z\n",
    "\n",
    "\n",
    "    def compute_geometry_loss(self, z, risk, time, event):\n",
    "\n",
    "        return self.geometry_reg(z, risk, time, event)\n",
    "\n",
    "    def counterfactual_gene(self, gene_ids, context_ids, gene_remove_idx):\n",
    "\n",
    "        gene_cf = self.counterfactual.remove_gene(\n",
    "            gene_ids,\n",
    "            gene_remove_idx\n",
    "        )\n",
    "\n",
    "        return self.forward(gene_cf, context_ids)\n",
    "\n",
    "    def counterfactual_treatment(self, gene_ids, context_ids, new_treatment_id):\n",
    "\n",
    "        context_cf = self.counterfactual.swap_treatment(\n",
    "            context_ids,\n",
    "            new_treatment_id\n",
    "        )\n",
    "\n",
    "        return self.forward(gene_ids, context_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccdc5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MSK-CHORD data...\n",
      "Building gene vocabulary...\n",
      "Building hypergraph...\n",
      "Building dataloaders...\n",
      "Initializing model...\n",
      "Training...\n",
      "Epoch 1/30 | Loss: 3.6850 | Val C-index: 0.4446\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# COX PARTIAL LIKELIHOOD LOSS\n",
    "###############################################################\n",
    "\n",
    "class CoxPHLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, risk, time, event):\n",
    "\n",
    "        # Sort by descending time\n",
    "        order = torch.argsort(time, descending=True)\n",
    "        risk = risk[order]\n",
    "        event = event[order]\n",
    "\n",
    "        log_cumsum = torch.logcumsumexp(risk, dim=0)\n",
    "\n",
    "        loss = -torch.sum((risk - log_cumsum) * event)\n",
    "\n",
    "        return loss / (event.sum() + 1e-6)\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# COUNTERFACTUAL CONSISTENCY LOSS\n",
    "###############################################################\n",
    "\n",
    "class CounterfactualConsistencyLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, original_risk, cf_risk):\n",
    "\n",
    "        return F.mse_loss(original_risk, cf_risk)\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# C-INDEX\n",
    "###############################################################\n",
    "\n",
    "def concordance_index(risk, time, event):\n",
    "\n",
    "    risk = risk.detach().cpu().numpy()\n",
    "    time = time.detach().cpu().numpy()\n",
    "    event = event.detach().cpu().numpy()\n",
    "\n",
    "    n = len(time)\n",
    "    num = 0\n",
    "    den = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if time[i] < time[j] and event[i] == 1:\n",
    "                den += 1\n",
    "                if risk[i] > risk[j]:\n",
    "                    num += 1\n",
    "                elif risk[i] == risk[j]:\n",
    "                    num += 0.5\n",
    "\n",
    "    if den == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return num / den\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# TRAINER\n",
    "###############################################################\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        config\n",
    "    ):\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.config = config\n",
    "\n",
    "        self.optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=config.lr,\n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "\n",
    "        self.cox_loss = CoxPHLoss()\n",
    "        self.cf_loss = CounterfactualConsistencyLoss()\n",
    "\n",
    "    def train_epoch(self):\n",
    "\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in self.train_loader:\n",
    "\n",
    "            gene_ids = batch[\"gene_ids\"].to(DEVICE)\n",
    "            context_ids = batch[\"context\"].to(DEVICE)\n",
    "            time = batch[\"time\"].to(DEVICE)\n",
    "            event = batch[\"event\"].to(DEVICE)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            risk, z = self.model(gene_ids, context_ids)\n",
    "\n",
    "            loss_cox = self.cox_loss(risk, time, event)\n",
    "\n",
    "            loss_geom = self.model.compute_geometry_loss(\n",
    "                z, risk, time, event\n",
    "            )\n",
    "\n",
    "            # Counterfactual (remove first gene index in batch)\n",
    "            gene_remove_idx = gene_ids[:, 0]\n",
    "            cf_risk, _ = self.model.counterfactual_gene(\n",
    "                gene_ids,\n",
    "                context_ids,\n",
    "                gene_remove_idx\n",
    "            )\n",
    "\n",
    "            loss_cf = self.cf_loss(risk, cf_risk)\n",
    "\n",
    "            total = (\n",
    "                loss_cox\n",
    "                + self.config.geometry_lambda * loss_geom\n",
    "                + self.config.counterfactual_lambda * loss_cf\n",
    "            )\n",
    "\n",
    "            total.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += total.item()\n",
    "\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    def validate(self):\n",
    "\n",
    "        self.model.eval()\n",
    "        all_risk = []\n",
    "        all_time = []\n",
    "        all_event = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "\n",
    "                gene_ids = batch[\"gene_ids\"].to(DEVICE)\n",
    "                context_ids = batch[\"context\"].to(DEVICE)\n",
    "                time = batch[\"time\"].to(DEVICE)\n",
    "                event = batch[\"event\"].to(DEVICE)\n",
    "\n",
    "                risk, _ = self.model(gene_ids, context_ids)\n",
    "\n",
    "                all_risk.append(risk)\n",
    "                all_time.append(time)\n",
    "                all_event.append(event)\n",
    "\n",
    "        risk = torch.cat(all_risk)\n",
    "        time = torch.cat(all_time)\n",
    "        event = torch.cat(all_event)\n",
    "\n",
    "        c_index = concordance_index(risk, time, event)\n",
    "\n",
    "        return c_index\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "        for epoch in range(self.config.epochs):\n",
    "\n",
    "            train_loss = self.train_epoch()\n",
    "            val_cindex = self.validate()\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{self.config.epochs} | \"\n",
    "                f\"Loss: {train_loss:.4f} | \"\n",
    "                f\"Val C-index: {val_cindex:.4f}\"\n",
    "            )\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# MAIN\n",
    "###############################################################\n",
    "\n",
    "def main():\n",
    "\n",
    "    print(\"Loading MSK-CHORD data...\")\n",
    "\n",
    "    loader = MSKDataLoader(CFG)\n",
    "    clinical_patient, clinical_sample, mutations, treatment = loader.load_raw()\n",
    "\n",
    "    preprocessor = MSKPreprocessor()\n",
    "    df = preprocessor.preprocess(\n",
    "        clinical_patient,\n",
    "        clinical_sample,\n",
    "        mutations,\n",
    "        treatment\n",
    "    )\n",
    "\n",
    "    print(\"Building gene vocabulary...\")\n",
    "    gene_vocab = GeneVocabulary(df)\n",
    "\n",
    "    print(\"Building hypergraph...\")\n",
    "    hyper_builder = HypergraphBuilder(\n",
    "        df,\n",
    "        gene_vocab.gene2idx\n",
    "    )\n",
    "\n",
    "    H_sparse = hyper_builder.build()\n",
    "\n",
    "    print(\"Building dataloaders...\")\n",
    "    train_loader, val_loader, treatment_encoder = build_dataloaders(\n",
    "        df,\n",
    "        gene_vocab\n",
    "    )\n",
    "\n",
    "    print(\"Initializing model...\")\n",
    "\n",
    "    model = MechanismHypergraphModel(\n",
    "        num_genes=len(gene_vocab),\n",
    "        num_treatments=len(treatment_encoder.classes_),\n",
    "        H_sparse=H_sparse\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        CFG\n",
    "    )\n",
    "\n",
    "    print(\"Training...\")\n",
    "    trainer.fit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58004870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
